{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "agricultura_familiar.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyO06akaPWLOPN8jZ20u0pFA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidwedder/yt_tutorials/blob/master/agricultura_familiar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAKqj0_Xg6n_"
      },
      "source": [
        "import pandas as pd \n",
        "url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data'\n",
        "base = pd.read_csv(url)\n",
        "base.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjOmuKKQWFiz"
      },
      "source": [
        "previsores = base.iloc[:,0:14].values\n",
        "classe = base.iloc[:,14].values\n",
        "print(classe)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDHZ3C0bWlVs"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_previsores = LabelEncoder()\n",
        "\n",
        "previsores[:,1] = label_previsores.fit_transform(previsores[:,1])\n",
        "previsores[:,3] = label_previsores.fit_transform(previsores[:,3])\n",
        "previsores[:,5] = label_previsores.fit_transform(previsores[:,5])\n",
        "previsores[:,6] = label_previsores.fit_transform(previsores[:,6])\n",
        "previsores[:,7] = label_previsores.fit_transform(previsores[:,7])\n",
        "previsores[:,8] = label_previsores.fit_transform(previsores[:,8])\n",
        "previsores[:,9] = label_previsores.fit_transform(previsores[:,9])\n",
        "previsores[:,13] = label_previsores.fit_transform(previsores[:,13])\n",
        "\n",
        "label_classe = LabelEncoder()\n",
        "\n",
        "# 1 coluna apenas\n",
        "classe = label_classe.fit_transform(classe)\n",
        "classe"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FV_qsg8eWx-l"
      },
      "source": [
        "#Boas práticas: Escalonamento de dados#\n",
        "# Padronizando os dados da variável previsores com o Standard Scale\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "previsores = scaler.fit_transform(previsores)\n",
        "\n",
        "previsores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1CRbIQKW2GY"
      },
      "source": [
        "#Treinamento e teste\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Previsores é o X e a classe é o Y, no contexto de outros exemplos \n",
        "previsores_treinamento, previsores_teste, classe_treinamento, classe_teste = train_test_split(previsores,classe,test_size = 0.5, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bs0Q2TDXE-f"
      },
      "source": [
        "#Classificação\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "classificador = GaussianNB()\n",
        "\n",
        "classificador.fit(previsores_treinamento, classe_treinamento)\n",
        "previsores = classificador.predict(previsores_teste)\n",
        "\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, average_precision_score\n",
        "# Matriz de confusão\n",
        "matriz = confusion_matrix(classe_teste, previsores)\n",
        "print(\"Matriz de confusão: \\n\", matriz)\n",
        "\n",
        "\n",
        "# Acuracia\n",
        "acuracia = accuracy_score(classe_teste,previsores)\n",
        "print(\"\\nAcurácia: \", acuracia)\n",
        "\n",
        "# Recall (Sensibilidade)\n",
        "recall = average_precision_score(classe_teste,previsores)\n",
        "print(\"\\nRecall: \", recall)\n",
        "\n",
        "# Recall manual:\n",
        "recall2 = 5898 / 6193\n",
        "print(\"\\nRecall Manual: \",recall2)\n",
        "\n",
        "# Precisao\n",
        "precisao = 5898 / (5898+1307)\n",
        "print(\"\\nPrecisão: \", precisao)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcXy4RrZXLbM"
      },
      "source": [
        "import numpy as np\n",
        "# APLICANDO Random Forest\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "# Ja importamos o train_test_split\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qUFSzpbXQfE"
      },
      "source": [
        "arveres = RandomForestRegressor(n_estimators=1000, random_state=0, n_jobs=-1)\n",
        "\n",
        "arveres.fit(previsores_treinamento,classe_treinamento)\n",
        "\n",
        "previsao1 = arveres.predict(previsores_teste)\n",
        "\n",
        "# Captura de erro:\n",
        "# Este é valor do erro da nossa árvore.\n",
        "np.sqrt(mean_squared_error(classe_teste, previsao1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awO2DN7lXyr1"
      },
      "source": [
        "Erro Default: 0.32034415998326055\n",
        "Erro com n_estimators=200: 0.3200829058950066\n",
        "Erro com n_estimators=500: 0.3196850473263169\n",
        "Erro com n_estimators=1000: 0.3195516359438612\n",
        "\n",
        "A diferença entre usar uma árvore e uma RandomForest é justamente a aleatoriedade aplicada na feature e nas linhas/amostras.\n",
        "Será criado uma amostra de reposição (bootstrap sampling ou bagging). Não é uma amostra fiél da realidade, mas sim uma maneira sintética de gerar mais amostras.\n",
        "\n",
        "Além disso, também é usado o conceito de Subspace Sampling.\n",
        "A ideia é usar 2 features aleatorias de cada amostra entre as N features."
      ]
    }
  ]
}